{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1facl6Apm3UCx8irDSe9rKU88f4Tsizsv",
      "authorship_tag": "ABX9TyM7caUT+bgoEbjPbrc4PxbW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bl4ckf0xk/ModelX_First_Order/blob/main/ModelX_Model_XGB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GroupShuffleSplit, StratifiedKFold, train_test_split, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, recall_score, precision_score\n",
        "import joblib"
      ],
      "metadata": {
        "id": "bSddWgyukfDB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "import shap"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzmndOz3kkxN",
        "outputId": "94573de9-0586-4d41-9515-d03f2ebd7dff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.50.0)\n",
            "Requirement already satisfied: numpy>=2 in /usr/local/lib/python3.12/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from shap) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/drive/MyDrive/Dementia Prediction Dataset.csv'\n",
        "MODEL_OUT = '/content/dementia_nonmedical_model.pkl'\n",
        "RANDOM_STATE = 42\n",
        "TARGET = 'DEMENTED'\n",
        "SUBJECT_ID = 'NACCID'  # change if your identifier column has a different name"
      ],
      "metadata": {
        "id": "nPj5rIMSk8t6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Data file not found at {path}. Upload it to Colab or set DATA_PATH correctly.\")\n",
        "    df = pd.read_csv(path)\n",
        "    return df"
      ],
      "metadata": {
        "id": "ugyYBlVslAI9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NON_MEDICAL_WHITELIST = [\n",
        "    # Subject demographics\n",
        "    'BIRTHYR', 'BIRTHMO', 'SEX', 'HISPANIC', 'HISPOR', 'HISPORX',\n",
        "    'RACE', 'RACEX', 'RACESEC', 'RACESECX', 'RACETER', 'RACETERX',\n",
        "    'EDUC', 'MARISTAT', 'PRIMLANG', 'PRIMLANX', 'RESIDENC', 'HANDED', 'NACCLIVS', 'INDEPEND',\n",
        "    # Co-participant\n",
        "    'INBIRYR', 'INBIRMO', 'INSEX', 'INHISP', 'INHISPOR', 'INHISPOX', 'INRACE', 'INRACEX', 'INRASEC', 'INRASECX', 'INRATER', 'INRATERX', 'INEDUC', 'INRELTO', 'INRELTOX', 'NEWINF',\n",
        "    # Lifestyle\n",
        "    'TOBAC30', 'TOBAC100', 'SMOKYRS', 'PACKSPER', 'QUITSMOK', 'ALCOCCAS', 'ALCFREQ',\n",
        "    # Visit metadata\n",
        "    'NACCVNUM', 'NACCNVST', 'NACCAVST', 'NACCDAYS', 'NACCFDYS', 'PACKET', 'FORMVER', 'TELCOV', 'TELMOD',\n",
        "    # Family history (non-genetic fields)\n",
        "    'NACCFAM', 'NACCMOM', 'NACCDAD'\n",
        "]"
      ],
      "metadata": {
        "id": "w3ZoQMSvlD78"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Loading data...')\n",
        "df = load_data(DATA_PATH)\n",
        "print('Rows:', len(df), 'Columns:', len(df.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5nvMH62lIPL",
        "outputId": "f07aa9ba-b0e0-4805-c26a-143f59563bd4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-175837067.py:4: DtypeWarning: Columns (20,22,24,26,28,41,44,46,48,51,61,63,65,67,69,71,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,134,156,165,176,179,189,217,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,256,258,260,262,264,266,268,270,272,382,397,399,401,419,421,423,432,445,454,494,574,605,613,638,674,690,704,707,710,715,727,738,744,746,803,804,809,810,811,812,820,831,833,835,837,843,904,959,960,961,969,970,971,972,982,1004,1007,1010) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 195196 Columns: 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure target and subject id exist\n",
        "if TARGET not in df.columns:\n",
        "    raise KeyError(f\"Target column '{TARGET}' not found in dataset.\")\n",
        "if SUBJECT_ID not in df.columns:\n",
        "    raise KeyError(f\"Subject ID column '{SUBJECT_ID}' not found in dataset.\")\n",
        "\n",
        "# Reduce to columns we care about (keep subject id and target)\n",
        "available_features = [c for c in NON_MEDICAL_WHITELIST if c in df.columns]\n",
        "print(f'Using {len(available_features)} non-medical features (of {len(NON_MEDICAL_WHITELIST)} whitelist)')\n",
        "\n",
        "# Warn about missing whitelist columns\n",
        "missing = set(NON_MEDICAL_WHITELIST) - set(available_features)\n",
        "if missing:\n",
        "    print('Warning: The following whitelist columns were not found in your CSV and will be skipped:')\n",
        "    print(sorted(list(missing)))\n",
        "\n",
        "keep_cols = [SUBJECT_ID, TARGET] + available_features\n",
        "df = df[keep_cols].copy()"
      ],
      "metadata": {
        "id": "yEQHJk-AloVb",
        "outputId": "0a5e251b-6548-48a1-a8d7-e90e5d466d44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 55 non-medical features (of 55 whitelist)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle NACC special codes -> convert common missing codes to NaN"
      ],
      "metadata": {
        "id": "qSKY5goUlzh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Typical NACC codes: -4 = Not applicable, -1 or 9 = Unknown, 88/99 = other/missing depending on variable\n",
        "NA_CODES = [-4, -1, 8, 9, 88, 95, 96, 97, 98, 99, 999]\n",
        "for v in df.columns:\n",
        "    if df[v].dtype.kind in 'biufc':\n",
        "        df[v] = df[v].replace(NA_CODES, np.nan)\n",
        "    else:\n",
        "        # for object/string fields, keep as-is and handle missing later\n",
        "        df[v] = df[v].replace([str(x) for x in NA_CODES], np.nan)\n",
        "\n",
        "# Also treat target code '9' explicitly as NaN (unknown)\n",
        "df[TARGET] = df[TARGET].replace(9, np.nan)\n",
        "\n",
        "# Drop rows where target is missing\n",
        "df = df[df[TARGET].notna()].copy()\n",
        "print('After dropping unknown target, rows:', len(df))"
      ],
      "metadata": {
        "id": "jSqXpbV_l2fG",
        "outputId": "96c4da3b-0d55-4f29-ab38-ffc96b5700dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After dropping unknown target, rows: 195196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature engineering"
      ],
      "metadata": {
        "id": "Cx3y9BiJl8U2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AGE if present; compute age-at-visit if possible using BIRTHYR and an approximate VISITYR if available.\n",
        "# If NACCAGE exists, prefer it. Otherwise derive AGE from BIRTHYR with caveat.\n",
        "if 'NACCAGE' in df.columns:\n",
        "    df['AGE'] = df['NACCAGE']\n",
        "elif 'BIRTHYR' in df.columns and 'NACCVNUM' in df.columns:\n",
        "    # cheaper approximation: assume visit year unknown; fallback to age buckets via EDUC if needed\n",
        "    df['AGE'] = np.nan\n",
        "else:\n",
        "    df['AGE'] = np.nan\n",
        "\n",
        "# Pack-years and simple booleans\n",
        "if 'PACKSPER' in df.columns and 'SMOKYRS' in df.columns:\n",
        "    df['PACK_YEARS'] = df['PACKSPER'] * df['SMOKYRS']\n",
        "else:\n",
        "    df['PACK_YEARS'] = np.nan\n",
        "\n",
        "if 'TOBAC30' in df.columns and 'TOBAC100' in df.columns:\n",
        "    df['EVER_SMOKE'] = ((df['TOBAC30'] == 1) | (df['TOBAC100'] == 1)).astype('Int64')\n",
        "else:\n",
        "    df['EVER_SMOKE'] = pd.Series([pd.NA] * len(df))\n",
        "\n",
        "# Heavy alcohol heuristic\n",
        "if 'ALCFREQ' in df.columns:\n",
        "    # interpret codes: (user should adjust according to their codebook)\n",
        "    # treat high frequency codes (e.g., weekly/daily) as heavy\n",
        "    df['HEAVY_ALCOHOL'] = df['ALCFREQ'].apply(lambda x: 1 if (pd.notna(x) and float(x) >= 5) else 0).astype('Int64')\n",
        "else:\n",
        "    df['HEAVY_ALCOHOL'] = pd.Series([pd.NA] * len(df))\n",
        "\n",
        "# Years in study\n",
        "if 'NACCDAYS' in df.columns:\n",
        "    df['YEARS_IN_STUDY'] = df['NACCDAYS'] / 365.25\n",
        "else:\n",
        "    df['YEARS_IN_STUDY'] = np.nan\n",
        "\n",
        "# Lives alone bool from NACCLIVS (if 1 = lives alone in your version)\n",
        "if 'NACCLIVS' in df.columns:\n",
        "    df['LIVES_ALONE'] = df['NACCLIVS'].apply(lambda x: 1 if x == 1 else 0).astype('Int64')\n",
        "else:\n",
        "    df['LIVES_ALONE'] = pd.Series([pd.NA] * len(df))\n",
        "\n",
        "# Final feature list (keep engineered features)\n",
        "engineered = ['AGE', 'PACK_YEARS', 'EVER_SMOKE', 'HEAVY_ALCOHOL', 'YEARS_IN_STUDY', 'LIVES_ALONE']\n",
        "for e in engineered:\n",
        "    if e not in df.columns:\n",
        "        df[e] = np.nan"
      ],
      "metadata": {
        "id": "Xo0srCM2mBXu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final feature set building (numeric vs categorical)"
      ],
      "metadata": {
        "id": "lje2VjF5mGMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start from available_features (from whitelist) and add engineered numeric features\n",
        "features = available_features.copy()\n",
        "# Remove potential duplicates if present\n",
        "for c in engineered:\n",
        "    if c not in features:\n",
        "        features.append(c)\n",
        "\n",
        "# Remove subject id and target if present mistakenly\n",
        "features = [f for f in features if f not in [SUBJECT_ID, TARGET]]\n",
        "\n",
        "# Separate numeric and categorical heuristically\n",
        "numeric_feats = []\n",
        "categorical_feats = []\n",
        "for f in features:\n",
        "    if pd.api.types.is_numeric_dtype(df[f]) or f in engineered:\n",
        "        numeric_feats.append(f)\n",
        "    else:\n",
        "        categorical_feats.append(f)\n",
        "\n",
        "print('Numeric features:', len(numeric_feats))\n",
        "print('Categorical features:', len(categorical_feats))"
      ],
      "metadata": {
        "id": "7kvtnCG-mJi6",
        "outputId": "24f162e0-7849-4cea-9ddf-66402c5cadca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric features: 50\n",
            "Categorical features: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing pipeline"
      ],
      "metadata": {
        "id": "Xr2yBHLWmNkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", numeric_transformer, numeric_feats),\n",
        "    (\"cat\", categorical_transformer, categorical_feats)\n",
        "])"
      ],
      "metadata": {
        "id": "xcgyi6UAmQUB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[features].copy()\n",
        "y = df[TARGET].astype(int)\n",
        "groups = df[SUBJECT_ID]\n",
        "\n",
        "# Group-aware train-test split: ensure subjects do not leak across splits\n",
        "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_STATE)\n",
        "train_idx, test_idx = next(gss.split(X, y, groups=groups))\n",
        "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "print('Train subjects:', groups.iloc[train_idx].nunique(), 'Test subjects:', groups.iloc[test_idx].nunique())"
      ],
      "metadata": {
        "id": "KD1n_-QgmlfA",
        "outputId": "4f7ecdf1-87fd-4388-ab5b-f99c06d781f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train subjects: 42029 Test subjects: 10508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model pipeline (XGBoost) + hyperparameter search"
      ],
      "metadata": {
        "id": "9L0Ky3EMmp7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# xgb_clf = XGBClassifier(\n",
        "#     objective='binary:logistic',\n",
        "#     use_label_encoder=False,\n",
        "#     eval_metric='auc',\n",
        "#     random_state=RANDOM_STATE,\n",
        "#     n_jobs=1\n",
        "# )\n",
        "\n",
        "# pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('clf', xgb_clf)])\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    tree_method='hist'\n",
        ")\n",
        "\n",
        "clf = Pipeline([\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"model\", model)\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "BRZKlSqXmtpq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train, y_train)\n",
        "print(\"Accuracy:\", clf.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "T3Yn9cQYsIQt",
        "outputId": "51978b3f-f6bd-4b99-e46a-8cfda7ae0af4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['AGE']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['AGE']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.902682691820072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHSB2FisyQ8a",
        "outputId": "abdd5f43-1c15-4d1d-dcaa-7375cfd4ae98"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['AGE']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix:\n",
            " [[26143  1880]\n",
            " [ 1958  9457]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93     28023\n",
            "           1       0.83      0.83      0.83     11415\n",
            "\n",
            "    accuracy                           0.90     39438\n",
            "   macro avg       0.88      0.88      0.88     39438\n",
            "weighted avg       0.90      0.90      0.90     39438\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(clf, \"dementia_pipeline_xgb.joblib\")\n",
        "print(\"Model saved as dementia_pipeline_xgb.joblib\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIEuAyoeyWUv",
        "outputId": "46db0a6d-67f3-4dfd-f57f-eb9d75413879"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as dementia_pipeline_xgb.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded = joblib.load(\"dementia_pipeline_xgb.joblib\")\n",
        "\n",
        "# Single prediction example (replace with real row)\n",
        "example = X_test.iloc[[0]]\n",
        "pred = loaded.predict(example)\n",
        "print(\"\\nPrediction for sample row:\", pred)\n",
        "\n",
        "import gc\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW_f6ySgyG4y",
        "outputId": "71b41316-0fdc-4a3f-e375-9cfef517a2e4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['AGE']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prediction for sample row: [0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "309"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# Load the full pipeline\n",
        "clf = joblib.load(\"dementia_pipeline_xgb.joblib\")\n",
        "\n",
        "# Example user input\n",
        "user_input = {\n",
        "    \"AGE\": 67,\n",
        "    \"EDUCATION\": \"High school\",\n",
        "    \"LIVES_WITH\": \"Spouse\",\n",
        "    \"SMOKING\": \"No\",\n",
        "    \"ALCOHOL\": \"Occasional\",\n",
        "    \"HEART_ATTACK\": \"No\",\n",
        "    \"STROKE\": \"Yes\",\n",
        "    \"EXERCISE\": \"Sometimes\"\n",
        "}\n",
        "\n",
        "# Build DataFrame with all pipeline features\n",
        "X_pred = pd.DataFrame(columns=clf.named_steps['preprocess'].feature_names_in_)\n",
        "X_pred.loc[0] = np.nan  # initialize row with NaNs\n",
        "\n",
        "# Fill in user input\n",
        "for k, v in user_input.items():\n",
        "    if k in X_pred.columns:\n",
        "        X_pred.loc[0, k] = v\n",
        "\n",
        "# Predict\n",
        "label = clf.predict(X_pred)[0]\n",
        "risk = clf.predict_proba(X_pred)[:,1][0] * 100\n",
        "\n",
        "print(\"Predicted label:\", \"At risk\" if label == 1 else \"Not at risk\")\n",
        "print(\"Estimated dementia risk: {:.2f}%\".format(risk))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfi73aFayz7E",
        "outputId": "faedbcf1-3fe1-4098-c43a-320e91bb5ba8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: Not at risk\n",
            "Estimated dementia risk: 5.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['AGE']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['AGE']. At least one non-missing value is needed for imputation with strategy='median'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}